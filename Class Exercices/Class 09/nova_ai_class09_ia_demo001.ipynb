{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requirements\n",
    "\n",
    "To use the vision APIs you will need to use the version 3.2 as the new version 4.0 is not yet fully supported in terms of all the features from 3.2 and also is not fully integrated on all regions.\n",
    "\n",
    "to use the precious version you need to deploy a new vision resource in Azure portal using the following link:\n",
    "[https://portal.azure.com/#create/Microsoft.CognitiveServicesComputerVision](https://portal.azure.com/#create/Microsoft.CognitiveServicesComputerVision)\n",
    "\n",
    "Use the key and endpoint from the newly created resource in the code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "subscription_key = \"VISON_KEY\" #vison keu\n",
    "endpoint = \"VISION_ENDPOINT\" #vision endpoint\n",
    "\n",
    "client = ImageAnalysisClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(subscription_key)\n",
    ")\n",
    "\n",
    "image_url = \"https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/media/quickstarts/presentation.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "\n",
    "# Get the image from the URL\n",
    "response = requests.get(image_url)\n",
    "\n",
    "# Open the image using PIL\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Display the image\n",
    "display(img)\n",
    "\n",
    "# convert image to byte object\n",
    "img_byte_arr = BytesIO()\n",
    "\n",
    "#get image length\n",
    "image_length = len(img_byte_arr.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.analyze_from_url(\n",
    "    image_url=image_url, \n",
    "    visual_features=[VisualFeatures.CAPTION, \n",
    "                     VisualFeatures.OBJECTS, \n",
    "                     VisualFeatures.DENSE_CAPTIONS, \n",
    "                     VisualFeatures.TAGS, \n",
    "                     VisualFeatures.SMART_CROPS, \n",
    "                     VisualFeatures.PEOPLE],\n",
    "    language=\"en\", #try \"pt\" for Portuguese\n",
    "    gender_neutral_caption=True, # you can set to False to get gendered captions\n",
    ")\n",
    "\n",
    "if result is not None:\n",
    "    print(json.dumps(result.as_dict(), indent=4))\n",
    "else:\n",
    "\n",
    "    error_details = sdk.ImageAnalysisErrorDetails.from_result(result)\n",
    "    print(\" Analysis failed.\")\n",
    "    print(\"   Error reason: {}\".format(error_details.reason))\n",
    "    print(\"   Error code: {}\".format(error_details.error_code))\n",
    "    print(\"   Error message: {}\".format(error_details.message))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
