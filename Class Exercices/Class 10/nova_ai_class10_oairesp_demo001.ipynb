{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_0de0e663186f28fb0069161b80e7d0819393128bba2c65afee\",\n",
      "  \"created_at\": 1763056512.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_0de0e663186f28fb0069161b81212c81938e664d86a3994998\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Sure! Imagine we're dealing with a computer program that learns to recognize objects in pictures. This program uses a type of model called a neural network, which functions somewhat like a brain, with lots of connections and layers. Now, let's say the model is very good at identifying cats because you've taught it using lots of cat pictures.\\n\\n### What is Catastrophic Forgetting?\\n\\nCatastrophic forgetting happens when you then teach this model to recognize dogs, and suddenly it forgets how to identify cats. It's as if learning the new task (dogs) overwrote the previous knowledge (cats).\\n\\n### Why Does This Occur?\\n\\n1. **Same Space for Learning:** The model uses the same \\\"space,\\\" like a big chalkboard, to store all kinds of knowledge. When you learn something new, you might accidentally erase what was already there to make room, because there's limited space.\\n\\n2. **Adjustable Parts:** The model adjusts its settings (like flipping switches) to learn new things. If those settings were important for recognizing one thing (cats), changing them maybe for another thing (dogs) can cause problems.\\n\\n### Why Is It a Problem?\\n\\nIt's a problem because we want the model to remember everything! If we must retrain it every time we want it to learn something new, it would be inefficient and not very useful for tasks where lots of new information comes in.\\n\\n### How Can We Fix It?\\n\\n1. **Elastic Weight Consolidation:** Think of this as putting \\\"reminders\\\" or \\\"sticky notes\\\" on the chalkboard to say, \\\"Hey, this spot is important; don’t erase it completely.\\\" This helps save key parts of the cat knowledge while learning dogs.\\n\\n2. **Memory Replay:** Imagine if the model could use flashcards to occasionally review cat pictures while learning about dogs. This way, it keeps its memory fresh.\\n\\n3. **Generative Replay:** Use a side-program like an artist that redraws cat pictures for the model to keep practicing even without having the original pictures available.\\n\\n4. **Separate Parts:** If we have different sections of the \\\"chalkboard\\\" for cats and dogs, learning in one section doesn’t affect what’s stored in another. This approach keeps knowledge separate to avoid mix-up.\\n\\nBy using these fixes, we try to ensure the model continues getting smarter without forgetting past lessons!\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": \"resp_0de0e663186f28fb0069161b7c1e8c819388099db1edf31e3c\",\n",
      "  \"prompt\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 345,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 470,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 815\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"safety_identifier\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "deployment_name='DEPLOYMENT_NAME' #This will correspond to the custom name you chose for your deployment when you deployed a model. \n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = \"ENDPOINT\", \n",
    "    api_key=\"KEY\",\n",
    "    api_version=\"2025-03-01-preview\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # replace with your model deployment name\n",
    "    input=\"Define and explain the concept of catastrophic forgetting?\"\n",
    ")\n",
    "\n",
    "second_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # replace with your model deployment name\n",
    "    previous_response_id=response.id,\n",
    "    input=[{\"role\": \"user\", \"content\": \"Explain this at a level that could be understood by a college freshman\"}]\n",
    ")\n",
    "print(second_response.model_dump_json(indent=2)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
